\documentclass[a4paper,11pt]{article}
\usepackage{CLARIN2015}
\usepackage[english]{babel}
%\usepackage{hyperref}{}

\usepackage{times}  
\usepackage{url}



\pagestyle{empty}
\begin{document}



\title{FoLiA in practice: The infrastructure of a linguistic annotation format}
\author{Maarten van Gompel$^a$ \and Ko van der
    Sloot$^a$ \and Martin Reynaert$^{ab}$ \and Antal van den Bosch$^c$} %cheating to get the affiliation footnotes right
\date{}


\maketitle
\renewcommand{\thefootnote}{\alph{footnote}}
\footnotetext[1]{Centre for Language and Speech Technology, Radboud University}
\footnotetext[2]{Tilburg Centre for Cognition and Communication, Tilburg University}
\footnotetext[3]{Centre for Language Studies, Radboud University}
\renewcommand{\thefootnote}{\arabic{footnote}}

\begin{abstract}
We present an overview of the software and data infrastructure around FoLiA, a
\textbf{Fo}rmat for \textbf{Li}nguistic \textbf{A}nnotation developed in the
scope of the CLARIN-NL project and other projects.  FoLiA aims to provide a
single unified file format accommodating a wide variety of linguistic
annotation types, preventing the proliferation of using different formats for
different annotation types. FoLiA is being developed in a bottom-up and
practice-driven fashion.  We have invested mainly in the creation of a rich
infrastructure of tools that enable developers and end-users to work with the
format. This work will present the current state of this infrastructure.
\end{abstract}


\section{Introduction}

CLARIN's aim is to deliver an infrastructure for researchers that work with
language data and tools. This is impossible without agreeing on standards with
regard to data formats. Standardisation is an important prerequisite for good
interoperability between the many language tools that have emerged within and
outside of the scope of the CLARIN project, and to ensure the various data sets
released are usable in practice..

In the field, however, we often encounter an abundance of ad-hoc formats. These are
data formats that are often characterised by one or more of the following traits:

\begin{itemize}
    \item They are only used once, often by one specific tool or for just one specific purpose;
    \item They are poorly formalised or not formalised at all, i.e. there is a lack of a formal schema and semantics;
    \item They are poorly documented;
    \item They are often rigid and hard to extend.
\end{itemize}

The use of such ad-hoc formats can be considered the opposite of proper
standardisation and is to be avoided in any large infrastructure project. 

CLARIN adheres to the following principles when it comes to standardisation:

\begin{itemize}
    \item Open standards are preferred over proprietary standards;
    \item Formats and protocols should be:
    \begin{itemize}
        \item well-documented
        \item verifiable
        \item proven (being used in practice);
    \end{itemize}
    \item Text-based formats are (where possible) preferred over binary formats.
\end{itemize}

At the onset of CLARIN, the Dutch and Flemish Natural Language Processing (NLP)
community lacked such a proper standard with respect to linguisitcally
annotated text, and ad-hoc formats were prevalent in the field.  In the scope
of CLARIN-NL project TTNWW, the NWO project DutchSemCor, and the STEVIN project
SoNaR, a new format for linguistic annotation was developed as a solution to
accommodate their representational needs, and so FoLiA (Format for Linguistic
Annotation) was created.

The aim of FoLiA is to provide a practical standard, following a generic
paradigm, for the linguistic annotation of primarily written text. To this end,
a wide variety of linguistic annotation types is supported. 

An extensive overview of the FoLiA format is presented in earlier work \cite{FOLIACLIN2013},
which also features a comparison with competing standards and full motivation
for the creation of FoLiA. Documentation of the format is also available
elsewhere \cite{FOLIADOC2014} and offers a reference guide to all elements and attributes
that FoLiA defines.  A brief summary of key features will be repeated in
Section~\ref{sec:overview}, but for the remainder we refer to these two prior
works.

In this current paper, we intend to focus on the \emph{practical} nature of the
format, or rather, on the infrastructure that is built around the format and
the ways in which it had been put to use in the scope of CLARIN and beyond.
Section~\ref{sec:philosophy} will explain our philosophy behind FoLiA and its
infrastructure. Section~\ref{sec:softwareinfrastructure} subsequently describes
the currently available software infrastructure for FoLiA.
Section~\ref{sec:datainfrastructure} describes some corpora that have been
delivered in FoLiA.

\section{Overview}
\label{sec:overview}

FoLiA is an XML-based format and defines specific XML elements for \emph{structure
annotation} (e.g. paragraphs, sentences, word tokens, lists, figures..) and
\emph{linguistic annotation} (e.g. part-of-speech, dependency relations,
syntax, named entites, etc..). FoLiA makes use of a combination of inline and
stand-off annotation, making proper use of the hierarchical nature of XML and
facilitating the job for parsers where possible. The format is fully language and
tagset independent as tagsets are defined seperately in \emph{FoLiA Set Definitions}
by users and never prescribed by FoLiA itself. Validation can proceed
on a shallow level, against a RelaxNG schema, as well as a deep level which
validates used tagsets against the set definition files.

The sets are at the core of the FoLiA paradigm, annotation elements take an
generic attribute named ``class''. These \emph{classes} pertain to a set and are
defined by whatever set definition the user decides to use. The set definition
defines all allowed classes and allows for links with data category registries
for formal semantic closure.

Other generic attributes besides ``class'' are attributes to denote the
annotator of a particular annotation, the annotator type (human or machine),
the confidence level of the annotation, the time of the annotation, and more.

FoLiA also allows for various types of \emph{higher-order annotation}, such as
the ability to include alternative annotations, as well as extensive support
for corrections on annotations. There is also the ability to link other
modalities such as audio fragments of speech, to structural elements. So even
though FoLiA is a primarily a format to annotate text documents, speech
transcripts are supported as well. 

For metadata CLARIN-NL has committed to the CMDI standard \cite{CMDI}.
Although FoLiA has simple native support for metadata, we see no
sense in reinventing the wheel and FoLiA is ideally used in combination with an
external metadata format such as CMDI whenever extensive metadata is desired. A
reference to the metadata file can be made in the header of the FoLiA document.

\section{Our philosophy}
\label{sec:philosophy}

Recall the CLARIN principle that a format should be proven and used in
practice. FoLiA has been designed in a bottom-up fashion taking especially this
principle to heart. Our focus is to solve real problems people face in the
field with regards to their linguistic representation needs, and to do so in a
generic fashion. The ambition is to deliver a single unified file format that
can effectively handle a multitude of annotation needs in a generic fashion.
The main motivation is to prevent the need to switch formats whenever an extra
annotation type is introduced, and to prevent the scenario in which a plethora
of different formats is used for different annotation types.

It is nevertheless always conceivable that a user's particular need is not yet
covered by the latest version of FoLiA; in such cases we gladly hear from the
user and expand FoLiA where necessary, in collaboration with the user. The
development of FoLiA has already proceeded for several years in such a
collaborative fashion, and various annotation types have been added in close
contact with end-users both from within CLARIN and beyond.

In our philosophy, the creation of a file format is useless without
similtaneously creating an infrastructure of tools to work with said format.
This has therefore been our main focus over the years and will the the subject
of the next section.

\section{Software Infrastructure}
\label{sec:softwareinfrastructure}

When we speak of a FoLiA software infrastructure we refer to a published set of
software, from whatever sources and for whatever architecture, that enable
people to work with FoLiA. Such an infrastructure in simple terms encompasses
anything that can either process or deliver the data in the format, we can
subdivide it into the following components:

\begin{enumerate}
\item programming libraries;
\item tools for validation;
\item tools for conversions from and to other formats;
\item tools for visualisation;
\item tools for searching/querying;
\item editing tools;
\item special-purpose tools; i.e. specialised tools that use the format but are
    not necessarily focussed on it. In the case of FoLiA, This includes Natural
    Language Processing or Information Retrieval tools that use the format as a
    input and/or output.
\end{enumerate}

The programming libraries and tools that are purely designed to visualise,
manipulate, or convert the format in basic ways can consider part of a
\emph{core layer} of the infrastructure, whereas the special-purpose tools can
be considered to constitute an outer layer.

As FoLiA is an XML-based format, the rich and well-established XML
infrastructure is open to its users as well. In fact, almost all FoLiA tools
effectively rely on the existing software infrastructure available for XML. 

It is possible to not use any of the FoLiA-specific tools and use the
infrastructure offered by XML directly. For instance, one can use XPath to
query a FoLiA document and XSL to transform it. To do so effectively, however,
the user/developer needs to be more familiar with the intricacies of FoLiA,
than when using a tool from the FoLiA infrastructure that abstracts over this
for the benefit of the user/developer.

Many of the tools of the core layer are available as command-line tools and are
bundled in two software packages: there is a Python-based \textbf{FoLiA Tools}
package\footnote{https://pypi.python.org/pypi/FoLiA-tools} and a \textbf{FoLiA
Utilities} package\footnote{https://github.com/LanguageMachines/foliautils}
consisting of tools written in C++. Both are built on the respective libraries.
There is some overlap in tools, but each also offers distinct tools the other
does not. It is therefore recommended to install both. These packages, and all
others tools pertaining to the FoLiA infrastructure developed at Radboud
University, are also bundled in our \textbf{LaMachine}
distribution.\footnote{http://proycon.github.io/LaMachine/, available as a
Virtual Machine, Docker package or local installation script}

We subscribe strongly to the CLARIN principle that standards should be open and
place a similar requirement on the infrastructure components we build. 

\subsection{Programming Libraries}

At the heart of the FoLiA infrastructure are the \emph{programming libraries} that
enable developers to work with documents in the format in their software. We
ourselves offer libraries for both Python and for C++.

Python is a widely popular high-level programming language in the academic
world, and the NLP world in particular.  The Python library for FoLiA enables
develops to quickly integrate support for FoLiA in their scripts. The library
is part of the larger \textbf{PyNLPl}
library\footnote{https://github.com/proycon/pynlpl} and is also available from the
Python Package Index. \footnote{https://pypi.python.org/pypi/PyNLPl} It is extensively documented and comes with tutorials for
users.

The Python library suffers from the performance drawback that any high-level
interpreted language has. Whenever faster processing is required, or
integration in high-performance tools is desired,
\textbf{libfolia}\footnote{https://github.com/languagemachines/libfolia}, the
FoliA library for C++, offers a better solution. The library is modelled after
the Python library, so both are similarly structured, employ a similar syntax
and the respective authors try to do their best to keep the libraries in sync.

A third popular language in the field is Java, but there is no Java-based FoLiA
library is available yet to our knowledge. Nevertheless, there are a number of
java-based tools in the FoLiA infrastructure that have been developed
without a common underlying FoLiA library.

\subsection{Validation}

We already touched upon the notion of shallow and deep validation.
FoLiA's syntax is formalized in a RelaxNG schema, and shallow validation can
therefore be done using any XML validator with support for RelaxNG. 

The tools \textbf{foliavalidator} and \textbf{folialint}\footnote{Part of
respectively \textbf{foliatools} and \textbf{foliautils}} also perform shallow validation, and
their usage is strongly recommended, or should even be considered mandatory,
for anybody producing FoLiA documents. Moreover, the former tool can optionally perform
deep validation as well, i.e. it can validate the used classes against the set
definitions.

\subsection{Conversion}

The FoLiA tools \& utilities collections contain tools for the conversion from and to
various different other formats:

\begin{itemize}
    \item Conversion to plaintext
    \item Conversion to HTML
    \item Conversion to simple columned data or CSV
    \item Conversion from/to ReStructuredText\footnote{http://docutils.sourceforge.net/rst.html}
    \item Conversion from/to DCOI XML format \cite{DCOI}
    \item Conversion from the Alpino XML format \cite{ALPINO}
    \item Conversion from ALTO DIDL format %TODO: martin, link?
    \item Conversion from hocr format  %TODO: martin, link?
    \item Conversion from page format  %TODO: martin, link?
\end{itemize}

Conversions may be limited by the source or target format. Conversion to
FoLiA's predecessor DCOI XML, for instance, is only possible for the subset of
elements that DCOI supports. Similarly, conversion to
ReStructuredText is limited
to text, its structure and markup, and does not include linguistic annotations.

Besides the in-house developed FoLiA tools, third parties also make available
converters from or to FoLiA. A notable case is
\textbf{OpenConvert}\footnote{https://github.com/INL/OpenConvert}, developed by the Institute for Dutch Lexicology (INL), which can convert from TEI, plaintext, Alto, Microsoft Word, and HTML to
FoLiA.

\subsection{Visualisation}

An XSL stylesheet is available to visualise FoLiA documents. It renders
documents and unobtrusively pops up with annotation information when hovering
over structural items such as words. A major advantage is that this form of
visualisation can be conducted entirely client-side in nearly every
web browser. The \textbf{folia2html} conversion tool also employs the same
stylesheet.

\subsection{Searching}

Tools for searching and querying FoLiA documents can be divided into two
categories:

\begin{enumerate}
 \item In-document search;
 \item Document retrieval systems / Corpus Search tools.
\end{enumerate}

At a low level, in-document search can be conducted with the command-line tool
\textbf{foliaquery}, part of the FoLiA tools. This tool reads one or more FoLiA
documents in memory (sequentially), executes a search query, and presents the
matching results. This, however, is not a solution that scales to large
numbers of documents as it takes a fair amount of time and memory to process a document.

Full document retrieval systems do not rely on such costly real-time processing
of the FoLiA documents, but construct smart indices from the original documents
and operate on these indices. The software \textbf{Blacklab} (back-end)
\cite{BLACKLAB} (front-end) \textbf{Whitelab} \cite{WHITELAB} are examples of this. They were
%TODO martin: referenties blacklab & whitelab and Whitelab constructed in the
CLARIN-NL project OpenSoNaR, and can operate on FoLiA documents. It has to be
added though, that unlike the low-level in-document search, such engines
typically only support a simpler subset of the annotation types supported by
FoLiA, such as Part-of-Speech tags and lemmas. At this moment, span annotation
types such as dependency relations, syntax and named entities, are not
supported yet. %TODO martin: is dat inderdaad zo?

As FoLiA is a highly expressive format, the need arose for a query language
tuned specifically to the idiosyncrasies of FoLiA. Although FoLiA can be
perfectly searched with XPath, formulating a robust query is not always trivial
and may require more in-depth knowledge of FoLiA. The \emph{FoLiA Query
Language} (FQL) was designed as a higher-level query language, covering all of
FoLiA, to make querying FoLiA documents easier. FQL is implemented alongside
the FoLiA Python library in
\textbf{PyNLPl}\footnote{https://pypi.python.org/pypi/PyNLPl/}. It is documented as part
of the FoLiA documentation \cite{FOLIADOC2014}.

FQL is a new and expressive query language. People in the field may be more
accustomed to simpler and established query languages such as the \emph{Corpus
Query Language (CQL)} \cite{CQL}, developed at the Corpora and Lexicons group,
IMS, at the University of Stuttgart in the early 1990s. For this reason,
\textbf{PyNLPl} includes a library that converts CQL to the more expressive but
verbose FQL has been implemented as well. The low-level query tool makes use of
both these libraries. In the next section we will discuss FQL further and
introduce higher-level tools in the FoLiA infrastructure that make use of it.

\subsection{Editing}

FQL has been designed in such a way that it is not just a language for passive
querying, but a language that allows active manipulation of FoLiA documents. In
other words, FQL is to FoLiA as SQL is to relational database tables.
Therefore, the \textbf{foliaquery} command-line tool and the FQL library it relies on
can not just be used to passively retrieve information, but also to actively
edit documents.

A FoLiA document server \footnote{https://github.com/proycon/foliadocserve} has
been constructed as a back-end for the editing of FoLiA documents. It is
implemented as a RESTful webservice, with a simple human-interface to manually
enter queries, and takes care of on demand loading and unloading documents in
memory and serialising them to disk. It maintains a browsable document
repository, which features \textbf{git} version control support.

Neither the command-line tool nor the document server offer an
interface adequate for human end-users to easily work with. To provide
such an environment, we have been developing the \textbf{FoLiA Linguistic Annotation Tool}
(\textbf{FLAT})\footnote{https://github.com/proycon/flat}. It is a modern
web-application that offers an interface for the visualisation and editing of
FoLiA documents. Under the hood, user-interface interactions are translated to FQL
queries and communicated to the aforementioned FoLiA document server.

Although not yet supporting all of FoLiA at the current stage, \textbf{FLAT} has already
been used succesfully in several annotation projects featuring student
assistants at Radboud University. Further development of FLAT is
planned for the CLARIN-NL successor project CLARIAH, with the aim of providing
a mature editing environment covering all of FoLiA.

\subsection{Special-purpose tools}

The previous sections discussed tools that can be considered part of the
core layer. In this section we will discuss the outer layer of tools, these are
tools that either take FoLiA as their input or deliver it as their output to
perform a specific and specialised task, usually an NLP task given our context.
It is a most essential layer to the infrastructure.

\begin{itemize}
\item \textbf{\textbf{Ucto}}\footnote{https://languagemachines.github.io/ucto} -- An advanced rule-based tokeniser for a variety of
    languages. Support FoLiA
    input and output. \cite{UCTO}
\item \textbf{\textbf{Frog}}\footnote{https://languagemachines.github.io/frog} -- An NLP suite for Dutch, implementing tokenisation (through
    ucto), Part-of-Speech tagging, Lemmatisation, Dependency Parsing, Named
    Entity Recognition, Shallow parsing and Morphological Analysis. Supports
    FoLiA input and output.
\item \textbf{\textbf{CLAM}}\footnote{https://proycon.github.io/clam} -- Turns command-line NLP tools into RESTful webservice with an
    interface for human end-users. It integrates the FoLiA viewer to visualise
    FoLiA documents. \cite{CLAM}
\item \textbf{\textbf{Ticcl}} -- Text-Induced Corpus Clean-up. Outputs FoLiA. Used in the
    CLARIN-NL project Ticclops and PhilosTEI. \cite{Reynaert2010} %TODO martin: is dit de goede om te citeren?
\item \textbf{\textbf{Gecco}}\footnote{https://github.com/proycon/gecco}  -- Generic Environment for Context-Aware Correction
    of Orthography: A spelling correction engine fully based on FoLiA. Powers
    \emph{Valkuil.net} and soon also \emph{Fowlt.net}.
\item \textbf{\textbf{T-Scan}}\footnote{https://github.com/proycon/tscan} -- A Dutch text analytics tool for readability
    prediction. \cite{TSCAN}
\item \textbf{\textbf{Cesax}} -- A co-reference editor for syntactically annotated XML corpora.
    Supports FoLiA import and output. \cite{CESAX} 
\item \textbf{\textbf{Colibri Core}}\footnote{https://proycon.github.io/colibri-core}-- A tool for the computation
    of corpus statistics on ngrams and skipgrams in a quick and
    memory-efficient way. It can import FoLiA documents, which it subsequently
    compresses to an internal optimised binary format.
\end{itemize}


\section{Data Infrastructure}
\label{sec:datainfrastructure}

A format's usefulness is not just determined by the tools
available, but also by the data sets delivered in the format.
The following corpora are currently delivered in FoLiA:

\begin{itemize}
    \item \textbf{Basilex} -- The Basilex corpus collects Dutch written language by children,
        and contains about 11.5 million words. It includes lexical semantic sense
        annotation.\cite{BASILEX}
    \item \textbf{DutchSemCor} -- The DutchSemCor project delivered a Dutch corpus annotated
        with lexical semantic senses. Part of the annotation was manual, and a
        part was tagged automatically with Word Sense Disambiguation system trained on
        the manual part. The corpus is based on SoNaR, as well as extra
        sources. \cite{DUTCHSEMCOR}
    \item \textbf{SoNaR-500} --  The STEVIN project SoNaR aimed to deliver a 500 million
        word corpus of written Dutch (including Flemish) from numerous sources.
        The corpus is annotated with Part-of-Speech tags, lemmas, and named
        entities. \cite{StevinSONAR2013}
    \item \textbf{Nederlab} - A digitisation of a huge collection of dutch
        newspapers throughout the ages. \cite{NEDERLAB}.
    \item \textbf{VU-DNC} -- A diachronic Dutch newspaper corpus with annotations of
        subjectivity. \cite{VUDNC}
\end{itemize}

In addition to corpora, the data part of the infrastructure also consists of a
growing number of Set
Definitions.\footnote{https://github.com/proycon/folia/tree/master/setdefinitions}

\section{Conclusion}
\label{sec:conclusion}

In this paper we have described the rich infrastructure that has been developed around
the Format for Linguistic Annotation (FoLiA). We emphasised the need for a
practical and proven format, in line with CLARIN's standardisation principle,
and hence placed the focus for this paper on the software and data
infrastructure. A more extensive overview of FoLiA itself and motivation for its
inception was presented in earlier work \cite{FOLIACLIN2013}.

Continued efforts in the CLARIN-NL successor CLARIAH ensure that the
developments on the infrastructure surrounding FoLiA will continue in the
foreseeable future.


\bibliographystyle{acl}
\bibliography{folia}  

\end{document}
